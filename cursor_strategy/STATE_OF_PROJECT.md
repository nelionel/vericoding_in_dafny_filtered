# STATE_OF_PROJECT

## MAIN GOAL

Run the `vericoding_in_dafny_filtered` evaluation suite against `Qwen/Qwen3-30B-A3B-Thinking-2507` using the available H200SXM resources, ensuring long-context support (≈100k tokens) via a vLLM server, and capture reproducible metrics/artifacts.

## PHASED IMPLEMENTATION PLAN

- Phase 1: Understand evaluation assets
  - Description: Inventory the evaluation dataset, scripts, and configs under `vericoding_in_dafny_filtered` (and any supporting code in `verifiable_rl`) to know how the eval should run end-to-end.
  - Key tasks: Read documentation/code, identify entrypoints, determine dependencies and expected outputs/logs.
  - Relevant paths: `vericoding_in_dafny_filtered/`, `verifiable_rl/verl/recipe/dafny/`.
- Phase 2: Provision runtime and serve model
  - Description: Stand up a vLLM server for `Qwen/Qwen3-30B-A3B-Thinking-2507` on the H200SXM node with long-context (≈100k) support, confirm health, and expose endpoint(s) expected by the eval harness.
  - Key tasks: Choose proper tensor/pipeline parallel config, configure max context, verify server readiness, document connection info.
  - Relevant paths: `models/`, runtime scripts, infra configs.
- Phase 3: Execute eval and collect artifacts
  - Description: Run the `vericoding_in_dafny_filtered` eval against the vLLM endpoint, monitor progress, and save outputs/metrics for review.
  - Key tasks: Launch eval command(s), handle retries/failures, gather logs/results, summarize run in HISTORY.
  - Current focus: cross-check OpenRouter outputs by running a 50-task hard-subset slice with `claude-haiku` to benchmark pass rates against the failing Qwen run.

## HISTORY

- 2025-11-16: Initialized strategy tracking scaffolding. Files: `cursor_strategy/STATE_OF_PROJECT.md`, `cursor_strategy/IMMEDIATE_GOAL.md`. Commands: `mkdir -p cursor_strategy`.
- 2025-11-16: Reviewed `vericoding_in_dafny_filtered` docs/CLI to capture evaluation entrypoint, backend flags, and required env variables before implementation. Files: `README.md`, `src/clean_eval/cli.py`, `scripts/serve_vllm_model.sh`, `env.template`. Commands: `ls`, `read_file`.
- 2025-11-16: Created `/workspace/tests` scaffolding, installed Dafny v4.11.0 under `vericoding_in_dafny_filtered/.local/dafny`, and updated `scripts/install_dafny.sh` to rely on `dafny verify` so the installer no longer requires dotnet. Files: `scripts/install_dafny.sh`. Commands: `mkdir -p /workspace/tests`, `bash scripts/install_dafny.sh --install-root /workspace/vericoding_in_dafny_filtered/.local/dafny --env-file /workspace/vericoding_in_dafny_filtered/.dafny_env -y`, `source .dafny_env`, `dafny verify /tmp/dafny_hello.dfy`.
- 2025-11-16: Provisioned repo-local Python env (`.venv`), installed `requirements.txt`, populated `.env` with Dafny/vLLM defaults, and confirmed `python -m clean_eval.cli --dry-run --limit 1` succeeds with `PYTHONPATH=/workspace/vericoding_in_dafny_filtered/src`. Files: `.env`. Commands: `python3 -m venv .venv`, `source .venv/bin/activate && pip install -r requirements.txt`, `cp env.template .env`, `python -m clean_eval.cli --dry-run --limit 1 --models qwen3-30b-thinking`.
- 2025-11-16: Downloaded `Qwen/Qwen3-30B-A3B-Thinking-2507` into `/workspace/models/Qwen__Qwen3-30B-A3B-Thinking-2507` (~58 GB) via `scripts/download_hf_model.sh`, confirming the on-disk path for the upcoming vLLM server. Commands: `MODELS_DIR=/workspace/models bash scripts/download_hf_model.sh Qwen/Qwen3-30B-A3B-Thinking-2507`, `du -sh /workspace/models/Qwen__Qwen3-30B-A3B-Thinking-2507`.
- 2025-11-16: Installed `vllm` (v0.11.0) inside the virtualenv and launched a background server on `0.0.0.0:8000` serving `qwen3-30b-a3b-thinking-100k` with `--max-model-len 100000`, `--max-num-batched-tokens 150000`, and `--gpu-memory-utilization 0.85`; logs live at `logs/vllm_server.log`, and the health check (`curl http://127.0.0.1:8000/v1/models`) succeeds. Commands: `source .venv/bin/activate && pip install 'vllm>=0.6.4'`, `bash scripts/serve_vllm_model.sh /workspace/models/Qwen__Qwen3-30B-A3B-Thinking-2507 ...`.
- 2025-11-16: Iterated on evaluation harness logging: enabled `VERICODING_TOKEN_LOG`, added `--vllm-max-tokens/--vllm-request-timeout` CLI flags, and wired those through `clean_eval.providers` so per-call token CSVs and raw responses land under `eval_results/`. Commands: `cat >> .env`, `python -m clean_eval.cli --eval-hardest --limit …`, edits to `src/clean_eval/cli.py` and `providers.py`.
- 2025-11-16: Ran multiple smoke tests (single-task and 5-task hard-subset slices) to capture debug artifacts (`eval_results/qwen3-30b-a3b-thinking-12k/debug/*`), uncovering two blockers: (1) vLLM rejecting requests when the server context (12 k) didn’t match the client’s 16 k default; (2) long completions timing out when `max_tokens` was set high without increasing the OpenAI client timeout. Guidance captured: pick `--vllm-max-tokens ≈ (server_max_len - prompt_tokens - safety_margin)` and always pass `--vllm-request-timeout` big enough for the expected generation latency. Logs: `logs/clean_eval_qwen3-30b-sample.log`, `logs/vllm_server.log`, token CSV `eval_results/token_usage_qwen3-30b-a3b-thinking-12k.csv`.
- 2025-11-16: Restored a fresh vLLM server with full 100 k context (`qwen3-30b-a3b-thinking-100k`, `--max-num-batched-tokens 200000`, `--gpu-memory-utilization 0.92`) and reran a single hard-subset task with `--vllm-max-tokens 8000`, `--vllm-request-timeout 600`. Requests now stay within the sequence budget, but the model still produces free-form prose instead of the JSON patch, so the JSON parser fails. Full-run eval has not been reattempted; next agent should get a single task to complete end-to-end before scaling.
- 2025-11-16: Built `src/clean_eval/sequence_length_search.py` (plus `run_for_model` return plumbing) to binary-search `--vllm-max-tokens` with automatic artifact capture. Initial probes (2.5 k–3.5 k tokens, 3 hardest specs) confirmed JSON failures stem from prompt adherence rather than hitting the sequence cap; binary-search run was interrupted once those failures persisted.
- 2025-11-17: Attempted 50-task hard-subset run via OpenRouter (`python -m clean_eval.cli --eval-hardest --limit 50 --models qwen3-30b-thinking --backend openrouter --max-iterations 1 --verbose`) to check JSON parsing outside vLLM; every request failed instantly with `401 No auth credentials found`. Resolved by exporting `OPENROUTER_API_KEY` in the active shell; ready to re-run now that credentials are confirmed. Artifacts/logs: `eval_results/openrouter_qwen3-30b-thinking_20251117_000050/clean_eval.log`.
- 2025-11-17: Re-ran the OpenRouter slice (limit 50, concurrency 3) with the API key set; every call returned 200 OK, so JSON parsing succeeded, but *all* completions failed verification with concrete Dafny syntax/typing errors (imperative helper bodies, leftover narrative text, `new real[]` allocations, etc.). Sample artifacts: `eval_results/openrouter_qwen3-30b-thinking_20251117_000656/results/qwen3-30b-thinking/DB0016_specs_impl.dfy`, `…/DT0246_specs_impl.dfy`, `…/DT0291_specs_impl.dfy`.
- 2025-11-17: Patched `apply_json_replacements` to walk every candidate `[` and decode the last valid JSON array (preferring fenced ```json blocks), preventing bracketed math like `[0..|s|-1]` from being misinterpreted as the payload. README now documents that OpenRouter “thinking” models don’t expose reasoning tokens; only latency changes.
- 2025-11-17: Verified Dafny install separately (`$DAFNY_PATH --version` → `4.11.0…`; ran `/tmp/dafny_smoke.dfy` successfully) to rule out broken tooling—the syntax errors in the eval results are genuine model output issues.
- 2025-11-17: Confirmed the OpenRouter backend already uses the dynamic sliding-window limiter (`--use-dynamic-rate-limit`, `rate_limiter.py`) and attempted the requested 50-task hard-subset run with `claude-haiku` (`python -m clean_eval.cli --eval-hardest --limit 50 --models claude-haiku --backend openrouter --rate-limit-rpm 90 --max-concurrent-tasks 8`). Every call returned `401 No auth credentials found`, so no Dafny code was generated; results live under `eval_results/claude-haiku` and `eval_results/claude-haiku_1`, with a 5-task verbose repro (showing the 401s) in `eval_results/claude_haiku_debug2/`. Need a working `OPENROUTER_API_KEY` before re-trying.
- 2025-11-17: Re-ran the 50-task Claude Haiku slice with the freshly supplied `OPENROUTER_API_KEY`; all requests now complete but still produce invalid JSON patches (multiple “JSON replacement count mismatch” errors) and ultimately 0/50 verifications passed. Artifacts: `/workspace/vericoding_in_dafny_filtered/eval_results/claude-haiku_2/`. Bug persists even with Claude, reinforcing that the harness needs prompt enforcement/sanitization rather than relying on model choice.
- 2025-11-17: Installed the upstream `vericoding` harness (`python src/vericoder.py`) in its own virtualenv, wired it to the benchmark specs at `/workspace/vericoding-benchmark/specs`, and ran `claude-4.5-sonnet` via OpenRouter: `python src/vericoder.py dafny /workspace/vericoding-benchmark/specs --llm claude-4.5-sonnet --limit 50 --workers 4 --api-rate-limit-delay 0 --no-wandb --iterations 3`. Result: 29/50 tasks verified (58 %) with artifacts under `/workspace/vericoding-benchmark/vericoder_claude-4.5-sonnet_17-11_15h44/`. Confirms the upstream prompt/tooling combination remains healthier than the `clean_eval` flow and can act as a reference for tightening prompts/sanitizers.
- 2025-11-17: Ran the clean evaluator against the first 50 specs in `hard_subset/dafny_flat/files` without the hardest-only filter (`python -m clean_eval.cli --tasks-dir … --limit 50 --models claude-4.5-sonnet --backend openrouter --max-iterations 3`) and observed 29/50 passes (58 %) with artifacts under `eval_results/claude-4.5-sonnet_3/`, demonstrating the harness works once it’s not restricted to the most pathological tasks.
- 2025-11-17: Immediately re-ran `clean_eval` with `--eval-hardest --limit 50` (difficulty ≥3 slice) and confirmed the regression persists: 0/50 passes landed in `eval_results/claude-4.5-sonnet_4/`, matching the earlier OpenRouter failures.
- 2025-11-17: Executed the classic `vericoder.py` harness on `/workspace/vericoding_in_dafny_filtered/hard_subset/dafny_flat/files` (`python vericoding/src/vericoder.py … --llm claude-4.5-sonnet --limit 50 --iterations 3`) and recovered 22/50 passes (44 %) with artifacts under `hard_subset/dafny_flat/vericoder_claude-4.5-sonnet_17-11_19h01/`, highlighting the gap between the upstream workflow and `clean_eval` on the same slice.
- 2025-11-17: Parsed `vericoding-benchmark/vericoding_results_v1.csv` (filtering to `Language=dafny` and difficulty ≥3 task IDs from the hard-subset metadata) to establish reference pass rates: best historical models (Claude Sonnet/Opus, GPT-5-mini) sit near 30–35 %, which aligns with the vericoder.py run and underscores how unusual the 0 % clean-eval result is.
- 2025-11-17: Compared the vendored harness (`vericoding_in_dafny_filtered/src/vericoding`) with upstream `/workspace/vericoding/src/vericoding` and confirmed they diverge (extra rate limiter + JSON parsing changes in the filtered repo). Also cross-checked the 50-task outputs: `clean_eval --eval-hardest` is exercising DB/DT specs (difficulty ≥3) while the `vericoder.py` run that hit 44 % only touched the early DA files (difficulty ≤2), so they are not the same dataset slice yet. Files: `cursor_strategy/IMMEDIATE_GOAL.md`, `vericoding_in_dafny_filtered/src/clean_eval/cli.py`, `vericoding_in_dafny_filtered/src/vericoding/core/*`, `vericoding/src/vericoding/*`, `eval_results/claude-4.5-sonnet_4/summary.txt`, `hard_subset/dafny_flat/vericoder_claude-4.5-sonnet_17-11_19h01/summary.txt`. Commands: `diff -qr vericoding/src/vericoding vericoding_in_dafny_filtered/src/vericoding`, `diff -u vericoding/config/language_config.toml vericoding_in_dafny_filtered/config/language_config.toml`.
- 2025-11-17: Mirrored the `clean_eval` hardest-task selector to build `/workspace/vericoding_in_dafny_filtered/hard_subset/dafny_flat/hardest_50_for_vericoder` and ran the canonical harness (`python src/vericoder.py ... --llm claude-4.5-sonnet --iterations 3 --workers 4 --limit 50`). All 50 calls failed immediately with `401 No auth credentials found`, so the pass rate remained 0/50 because no tokens were issued. Next action: secure a working `OPENROUTER_API_KEY` for this shell (or switch the run to vLLM/local backend) before reattempting. Files: `hardest_50_for_vericoder/selected_tasks.txt`, `hard_subset/dafny_flat/vericoder_claude-4.5-sonnet_17-11_19h48/summary.txt`. Commands: `python - <<'PY' ...`, `python src/vericoder.py ...`.
- 2025-11-17: Re-ran `vericoder.py` on the same hardest-50 slice with a valid OpenRouter key; despite 150 successful API calls (≈560k tokens), the canonical harness still finished 0/50 (`vericoder_claude-4.5-sonnet_17-11_19h51`). Failures mirror the clean-eval logs—JSON replacements succeed but every iteration ends in Dafny parse/trigger errors or explicit verifier timeouts, often after the LLM injects helper prose (e.g., “Looking at the error…” blocks) that survives sanitization. Conclusion: the pass-rate collapse is inherent to the hardest metadata slice, not a harness-specific regression. Files: `hard_subset/dafny_flat/vericoder_claude-4.5-sonnet_17-11_19h51/summary.txt`, `.../results.csv`. Command: `python src/vericoder.py dafny ... --llm claude-4.5-sonnet --iterations 3 --limit 50 --no-wandb`.
- 2025-11-17: Built a “difficulty=2” control set (`hard_subset/dafny_flat/difficulty2_50_for_eval/files`, manifest + metadata) and ran both harnesses with Claude 4.5 Sonnet. `clean_eval` scored 30/50 (60 %) with artifacts in `eval_results/claude-4.5-sonnet_diff2_clean_rerun/claude-4.5-sonnet/`, while `vericoder.py` reached 15/50 (30 %) under `/workspace/vericoding_in_dafny_filtered/hard_subset/dafny_flat/vericoder_claude-4.5-sonnet_17-11_20h11/`. The gap shows the pipelines remain behaviorally different even on non-hard tasks; next work should focus on harmonizing prompts/sanitizers rather than assuming equivalence. Commands: `python - <<'PY' ...` (subset + metadata), `python -m clean_eval.cli --tasks-dir ...difficulty2_50_for_eval --models claude-4.5-sonnet --backend openrouter`, `python src/vericoder.py dafny ...difficulty2_50_for_eval --llm claude-4.5-sonnet --iterations 3`.
- 2025-11-17: Noted runtime divergence on the same difficulty-2 slice: `clean_eval` (20 workers, OpenRouter) finished in ~8 min (`summary.txt` shows 30/50), whereas `vericoder.py` (4 threads) took ~11 min (`Total processing time: 681 s`), reinforcing that the pipelines aren’t interchangeable in throughput either. Next tuning pass should log concurrency/iteration knobs so future comparisons are apples-to-apples.
- 2025-11-17: Updated the canonical `src/vericoder.py` to honor a configurable output root: new `--output-root` (and `VERICODER_OUTPUT_ROOT`) flags default to the nearest `eval_results/` ancestor, so datasets under `hard_subset/...` now emit artifacts in `.../eval_results/vericoder_<llm>_<timestamp>/` unless overridden. Files: `/workspace/vericoding/src/vericoder.py`, docs in `cursor_strategy/IMMEDIATE_GOAL.md`. Commands: `python src/vericoder.py dafny hard_subset/... --llm claude-4.5-sonnet --output-root /tmp/custom_results` (manual validation).
